#!/usr/bin/env python3
"""
æ¯æ—¥18æ™‚è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
JSDAã‹ã‚‰æœ€æ–°ã®å›½å‚µé‡‘åˆ©ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦Supabaseã«æ ¼ç´
"""
import os
import sys
import logging
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from data.processors.bond_data_processor import BondDataProcessor
from data.utils.database_manager import DatabaseManager
from data.collectors.boj.holdings_collector import BOJHoldingsCollector
from data.collectors.mof.bond_auction_web_collector import BondAuctionWebCollector

# JSTå®šç¾©
JST = timezone(timedelta(hours=9))

# ãƒ­ã‚°è¨­å®šï¼ˆCloud Runå¯¾å¿œï¼šãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ãªã—ã€æ¨™æº–å‡ºåŠ›ã®ã¿ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DailyDataCollector:
    """æ¯æ—¥ã®ãƒ‡ãƒ¼ã‚¿åé›†ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.processor = BondDataProcessor()
        self.db_manager = DatabaseManager()
        self.boj_collector = BOJHoldingsCollector(delay_seconds=2.0)
        self.mof_collector = BondAuctionWebCollector()

    def get_target_date(self):
        """
        å–å¾—å¯¾è±¡æ—¥ä»˜ã‚’æ±ºå®š
        ç¥æ—¥ãƒ»åœŸæ—¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®å¹³æ—¥ã‚’å–å¾—
        """
        import jpholiday

        # ç¿Œæ—¥ã‹ã‚‰é–‹å§‹ (JSTåŸºæº–)
        target_date = datetime.now(JST) + timedelta(days=1)

        # æœ€å¤§10æ—¥å…ˆã¾ã§ç¢ºèªï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
        for _ in range(10):
            # å¹³æ—¥ã‹ã¤ç¥æ—¥ã§ãªã„å ´åˆ
            if target_date.weekday() < 5 and not jpholiday.is_holiday(target_date.date()):
                result = target_date.strftime('%Y-%m-%d')
                logger.info(f"Target date determined: {result} (å¹³æ—¥)")
                return result

            # ç¥æ—¥ãƒ»åœŸæ—¥ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if target_date.weekday() >= 5:
                logger.info(f"Skipping weekend: {target_date.strftime('%Y-%m-%d')} ({target_date.strftime('%A')})")
            elif jpholiday.is_holiday(target_date.date()):
                holiday_name = jpholiday.is_holiday_name(target_date.date())
                logger.info(f"Skipping holiday: {target_date.strftime('%Y-%m-%d')} ({holiday_name})")

            # ç¿Œæ—¥ã«é€²ã‚€
            target_date += timedelta(days=1)

        # 10æ—¥å…ˆã¾ã§å¹³æ—¥ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼ˆé€šå¸¸ã‚ã‚Šãˆãªã„ï¼‰
        fallback = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
        logger.warning(f"Could not find weekday within 10 days, using fallback: {fallback}")
        return fallback

    def collect_daily_data(self):
        """æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        try:
            logger.info("=== æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ ===")
            
            overall_success = True

            # 1. JSDAãƒ‡ãƒ¼ã‚¿åé›†
            target_date_str = self.get_target_date()
            jsda_saved = self.collect_single_day_data(target_date_str)
            
            if jsda_saved < 0:
                logger.error("JSDAãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—")
                overall_success = False
            elif jsda_saved == 0:
                logger.info("JSDAãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆä¼‘æ—¥ã®å¯èƒ½æ€§ï¼‰")
            else:
                logger.info(f"JSDAãƒ‡ãƒ¼ã‚¿åé›†æˆåŠŸ: {jsda_saved}ä»¶")

            # 2. MOFå…¥æœ­ãƒ‡ãƒ¼ã‚¿åé›† (ç‹¬ç«‹ã—ã¦å®Ÿè¡Œ)
            if not self.mof_collector.sync_with_database():
                logger.warning("MOFãƒ‡ãƒ¼ã‚¿åé›†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")

            # 3. BOJä¿æœ‰ãƒ‡ãƒ¼ã‚¿åé›† (ç‹¬ç«‹ã—ã¦å®Ÿè¡Œ)
            if not self.boj_collector.sync_with_database():
                logger.warning("BOJãƒ‡ãƒ¼ã‚¿åé›†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")

            logger.info(f"=== æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº† (JSDAæˆåŠŸ: {overall_success}) ===")
            return overall_success

        except Exception as e:
            logger.error(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã«è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            return False

    def _calculate_market_amount_for_record(self, bond_code: str, trade_date: str):
        """
        1ãƒ¬ã‚³ãƒ¼ãƒ‰åˆ†ã®market_amountã‚’è¨ˆç®—

        Args:
            bond_code: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            trade_date: å–å¼•æ—¥ (YYYY-MM-DD)

        Returns:
            market_amount (å„„å††), è¨ˆç®—ä¸å¯æ™‚ã¯None
        """
        try:
            # MarketAmountCalculatorã‚¯ãƒ©ã‚¹ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
            from data.utils.market_amount_calculator import MarketAmountCalculator

            calculator = MarketAmountCalculator()
            auction_history = calculator.get_auction_history(bond_code)
            boj_history = calculator.get_boj_holdings_history(bond_code)

            # ç´¯ç©ç™ºè¡Œé¡
            cumulative = calculator.calculate_cumulative_issuance(
                auction_history, trade_date
            )
            if cumulative is None:
                return None  # ç™ºè¡Œå‰

            # æ—¥éŠ€ä¿æœ‰é¡
            boj_holding = calculator.get_latest_boj_holding(boj_history, trade_date)

            # å¸‚ä¸­æ®‹å­˜é¡
            if boj_holding is not None:
                return cumulative - boj_holding
            else:
                return cumulative

        except Exception as e:
            logger.error(f"market_amountè¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({bond_code}, {trade_date}): {e}")
            return None

    def collect_single_day_data(self, target_date_str, retry_count=1):
        """
        1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆsimple_multi_day_collector.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        """
        from datetime import date

        max_retries = retry_count

        for attempt in range(max_retries + 1):
            try:
                logger.info(f"ğŸ“… åé›†ä¸­: {target_date_str} (è©¦è¡Œ {attempt + 1}/{max_retries + 1})")

                # æ—¥ä»˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                target_date = date.fromisoformat(target_date_str)

                # 1. CSVãƒ‡ãƒ¼ã‚¿å–å¾—
                # download_data_for_dateã‚’ä½¿ç”¨ï¼ˆå¹´ã¾ãŸãå¯¾å¿œï¼‰
                raw_df = self.processor.download_data_for_date(target_date)

                if raw_df is None:
                    logger.warning(f"  âŒ CSVãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {target_date_str}")
                    if attempt < max_retries:
                        logger.info("  â±ï¸  5ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤")
                        time.sleep(5)
                    continue

                if raw_df.empty:
                    logger.info(f"  ğŸ“­ ãƒ‡ãƒ¼ã‚¿ãŒç©ºï¼ˆä¼‘æ—¥ã®å¯èƒ½æ€§ï¼‰: {target_date_str}")
                    return 0

                # 2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                processed_df = self.processor.process_raw_data(raw_df)

                if processed_df.empty:
                    logger.info(f"  ğŸ“­ å‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿ãŒç©º: {target_date_str}")
                    return 0

                # 3. trade_dateã®æ¤œè¨¼ã¨è£œå®Œ
                
                # HTMLæƒ…å ±ã«åŸºã¥ãæ­£ç¢ºãªå–å¼•æ—¥ã®ç‰¹å®šï¼ˆ2026/1/5å•é¡Œå¯¾å¿œï¼‰
                actual_trade_date = None
                try:
                    actual_trade_date = self.processor.determine_trade_date_from_html(target_date)
                except Exception as e:
                    logger.warning(f"  âš ï¸  HTMLæ—¥ä»˜ç‰¹å®šå¤±æ•—: {e}")

                if actual_trade_date:
                    logger.info(f"  ğŸ“… HTMLæƒ…å ±ã«ã‚ˆã‚Šå–å¼•æ—¥ã‚’ä¿®æ­£: {target_date_str} -> {actual_trade_date}")
                    processed_df['trade_date'] = actual_trade_date.isoformat()
                elif 'trade_date' in processed_df.columns:
                    # CSVå†…ã®æ—¥ä»˜ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ—¥ä»˜ãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèªï¼ˆãƒ­ã‚°å‡ºåŠ›ã®ã¿ï¼‰
                    csv_dates = processed_df['trade_date'].unique()
                    if len(csv_dates) > 0 and csv_dates[0] != target_date_str:
                        logger.warning(f"  âš ï¸  æ—¥ä»˜ä¸ä¸€è‡´: CSVå†…={csv_dates[0]}, æŒ‡å®š={target_date_str}")
                        # JSDAã®ä»•æ§˜ä¸Šã€ãƒ•ã‚¡ã‚¤ãƒ«åã®æ—¥ä»˜(å…¬è¡¨æ—¥)ã¨ä¸­èº«ã®æ—¥ä»˜(å…¬è¡¨æ—¥)ã¯ä¸€è‡´ã™ã‚‹ã¯ãšã ãŒã€
                        # ä¸‡ãŒä¸€ä¸ä¸€è‡´ã§ã‚‚ã€ç®¡ç†ä¸Šã®æ—¥ä»˜(target_date_str)ã‚’å„ªå…ˆã™ã‚‹å ´åˆã¯ä¸Šæ›¸ãã™ã‚‹ã€‚
                        # ã“ã“ã§ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ…£ç¿’ã«å¾“ã„ã€å¼•æ•°ã§æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ã‚’å„ªå…ˆã—ã¦ä¸Šæ›¸ãã™ã‚‹ã€‚
                        processed_df['trade_date'] = target_date_str
                else:
                    # trade_dateãŒãªã„å ´åˆã¯ä»˜ä¸
                    processed_df['trade_date'] = target_date_str

                # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‰ã«market_amountè¨ˆç®—
                batch_data = processed_df.to_dict('records')

                # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«market_amountã‚’è¿½åŠ 
                logger.info(f"  ğŸ”¢ å¸‚ä¸­æ®‹å­˜é¡è¨ˆç®—ä¸­: {len(batch_data)}ä»¶")
                for record in batch_data:
                    bond_code = record.get('bond_code')
                    if bond_code:
                        market_amount = self._calculate_market_amount_for_record(
                            bond_code, target_date_str
                        )
                        record['market_amount'] = market_amount

                # 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                saved_count = self.db_manager.batch_insert_data(batch_data)

                if saved_count > 0:
                    logger.info(f"  âœ… æˆåŠŸ: {saved_count}ä»¶ä¿å­˜")
                    return saved_count
                else:
                    logger.warning(f"  âš ï¸  ä¿å­˜å¤±æ•—: {target_date_str}")
                    return -1

            except Exception as e:
                error_msg = str(e)
                is_timeout = "timeout" in error_msg.lower() or "connection" in error_msg.lower()

                if attempt < max_retries:
                    if is_timeout:
                        logger.warning(f"  â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {error_msg}")
                        logger.info("  â±ï¸  5åˆ†å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤")
                        time.sleep(300)  # 5åˆ†å¾…æ©Ÿ
                    else:
                        logger.warning(f"  âš ï¸  ä¸€èˆ¬ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {error_msg}")
                        logger.info("  â±ï¸  3åˆ†å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤")
                        time.sleep(180)  # 3åˆ†å¾…æ©Ÿ
                else:
                    logger.error(f"  âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ: {error_msg}")
                    return -1

        return -1

    def run_safety_checks(self):
        """å®Ÿè¡Œå‰ã®å®‰å…¨ç¢ºèª"""
        try:
            # ä»–ã®Pythonãƒ—ãƒ­ã‚»ã‚¹ãƒã‚§ãƒƒã‚¯
            import subprocess
            try:
                result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
                processes = result.stdout
                jsda_processes = [line for line in processes.split('\n')
                                if 'python' in line and ('collector' in line or 'jsda' in line.lower())]

                if len(jsda_processes) > 1:  # ç¾åœ¨ã®ãƒ—ãƒ­ã‚»ã‚¹ä»¥å¤–ã«ã‚‚ã‚ã‚‹
                    logger.warning("ä»–ã®JSDAåé›†ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œä¸­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                    for proc in jsda_processes:
                        logger.info(f"  ãƒ—ãƒ­ã‚»ã‚¹: {proc.strip()}")

            except Exception as e:
                logger.warning(f"ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

            # DBæ¥ç¶šç¢ºèª
            try:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°å–å¾—ã§æ¥ç¶šç¢ºèªï¼‰
                record_count = self.db_manager.get_total_record_count()
                if record_count >= 0:
                    logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª: {record_count}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨")
                else:
                    logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¯æˆåŠŸã—ã¾ã—ãŸãŒã€ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°å–å¾—ã«å¤±æ•—")

            except Exception as e:
                logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
                return False

            logger.info("å®‰å…¨ç¢ºèªãƒã‚§ãƒƒã‚¯å®Œäº†")
            return True

        except Exception as e:
            logger.error(f"å®‰å…¨ç¢ºèªãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("Daily Data Collector Started")

    try:
        collector = DailyDataCollector()

        # å®Ÿè¡Œå‰å®‰å…¨ç¢ºèª
        if not collector.run_safety_checks():
            logger.error("å®‰å…¨ç¢ºèªãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å®Ÿè¡Œã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            sys.exit(1)

        # ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œ
        success = collector.collect_daily_data()

        if success:
            logger.info("æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            sys.exit(0)
        else:
            logger.error("æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()