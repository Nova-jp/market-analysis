#!/usr/bin/env python3
"""
æœ€è¿‘ã®trade_dateä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
- æŒ‡å®šæ—¥ä»¥é™ã®trade_dateã‚’1å–¶æ¥­æ—¥å‰ã«ãšã‚‰ã™
- trade_dateä¿®æ­£å¾Œã«æ—§æ–¹å¼ã§è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£

ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :
1. æŒ‡å®šæ—¥ä»¥é™ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªtrade_dateã‚’å–å¾—
2. å„æ—¥ä»˜ã«ã¤ã„ã¦ã€1å–¶æ¥­æ—¥å‰ã®æ—¥ä»˜ã‚’è¨ˆç®—
3. è©²å½“ã™ã‚‹ã™ã¹ã¦ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°

ä½¿ç”¨æ–¹æ³•:
    python scripts/fix_recent_trade_date.py --from-date 2025-12-05
"""

import os
import sys
import argparse
from pathlib import Path
from supabase import create_client, Client
from dotenv import load_dotenv
import logging
from datetime import datetime, timedelta
import jpholiday

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/fix_recent_trade_date.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


def is_business_day(date_obj):
    """å–¶æ¥­æ—¥ã‹ã©ã†ã‹åˆ¤å®š"""
    if date_obj.weekday() >= 5:  # åœŸæ›œ=5, æ—¥æ›œ=6
        return False
    if jpholiday.is_holiday(date_obj):
        return False
    return True


def get_previous_business_day(date_obj):
    """å‰ã®å–¶æ¥­æ—¥ã‚’å–å¾—"""
    prev_day = date_obj - timedelta(days=1)
    while not is_business_day(prev_day):
        prev_day -= timedelta(days=1)
    return prev_day


def main():
    parser = argparse.ArgumentParser(description='æœ€è¿‘ã®trade_dateã‚’1å–¶æ¥­æ—¥å‰ã«ä¿®æ­£')
    parser.add_argument('--from-date', required=True, help='ä¿®æ­£é–‹å§‹æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿè¡Œã›ãšã«ç¢ºèªã®ã¿')

    args = parser.parse_args()

    from_date_str = args.from_date
    dry_run = args.dry_run

    logger.info("======================================================================")
    logger.info("trade_date ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ï¼‰")
    logger.info("======================================================================")
    logger.info(f"  ä¿®æ­£é–‹å§‹æ—¥: {from_date_str} ä»¥é™")
    logger.info(f"  ãƒ¢ãƒ¼ãƒ‰: {'DRY RUNï¼ˆç¢ºèªã®ã¿ï¼‰' if dry_run else 'æœ¬ç•ªå®Ÿè¡Œ'}")
    logger.info("======================================================================")
    logger.info("")

    # æ—¥ä»˜å½¢å¼ãƒã‚§ãƒƒã‚¯
    try:
        from_date = datetime.strptime(from_date_str, '%Y-%m-%d').date()
    except ValueError:
        logger.error("âŒ æ—¥ä»˜å½¢å¼ãŒä¸æ­£ã§ã™ã€‚YYYY-MM-DDå½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„")
        return

    # Supabaseæ¥ç¶š
    url = os.getenv('SUPABASE_URL')
    key = os.getenv('SUPABASE_KEY')

    if not url or not key:
        logger.error("âŒ ç’°å¢ƒå¤‰æ•° SUPABASE_URL, SUPABASE_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    supabase: Client = create_client(url, key)
    logger.info("âœ… Supabaseæ¥ç¶šæˆåŠŸ")
    logger.info("")

    # å¯¾è±¡æ—¥ä»˜ã‚’å–å¾—
    logger.info(f"ğŸ“¥ {from_date_str} ä»¥é™ã®trade_dateä¸€è¦§ã‚’å–å¾—ä¸­...")

    try:
        response = supabase.table('bond_data') \
            .select('trade_date') \
            .gte('trade_date', from_date_str) \
            .execute()

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆã‚½ãƒ¼ãƒˆï¼‰
        unique_dates = sorted(list(set([row['trade_date'] for row in response.data])))

        logger.info(f"  âœ… å–å¾—å®Œäº†: {len(unique_dates)}æ—¥åˆ†")
        logger.info("")

        if not unique_dates:
            logger.warning("âš ï¸  å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        # æ—¥ä»˜ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        logger.info("ğŸ”§ æ—¥ä»˜ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆä¸­...")
        logger.info("-" * 70)

        date_mappings = []

        for date_str in unique_dates:
            current_date = datetime.strptime(date_str, '%Y-%m-%d').date()
            previous_business_day = get_previous_business_day(current_date)

            mapping = {
                'old_date': date_str,
                'new_date': str(previous_business_day)
            }
            date_mappings.append(mapping)

            logger.info(f"  {date_str} â†’ {previous_business_day}")

        logger.info("")
        logger.info(f"  âœ… ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆå®Œäº†: {len(date_mappings)}æ—¥åˆ†")
        logger.info("")

        # ç¢ºèª
        if dry_run:
            logger.info("=" * 70)
            logger.info("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰ - å®Ÿè¡Œå†…å®¹ã®ç¢ºèª")
            logger.info("=" * 70)
            logger.info(f"  ä¿®æ­£å¯¾è±¡æ—¥æ•°: {len(date_mappings)}æ—¥")
            logger.info(f"  æœ€åˆã®æ—¥ä»˜: {date_mappings[0]['old_date']} â†’ {date_mappings[0]['new_date']}")
            logger.info(f"  æœ€å¾Œã®æ—¥ä»˜: {date_mappings[-1]['old_date']} â†’ {date_mappings[-1]['new_date']}")
            logger.info("")
            logger.info("æœ¬ç•ªå®Ÿè¡Œã™ã‚‹å ´åˆã¯ --dry-run ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å¤–ã—ã¦ãã ã•ã„")
            logger.info("=" * 70)
            return

        # å®Ÿè¡Œç¢ºèª
        logger.info("=" * 70)
        logger.warning("âš ï¸  ä»¥ä¸‹ã®å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™:")
        logger.info("=" * 70)
        logger.info(f"  ä¿®æ­£å¯¾è±¡æ—¥æ•°: {len(date_mappings)}æ—¥")
        logger.info(f"  æœ€åˆã®æ—¥ä»˜: {date_mappings[0]['old_date']} â†’ {date_mappings[0]['new_date']}")
        logger.info(f"  æœ€å¾Œã®æ—¥ä»˜: {date_mappings[-1]['old_date']} â†’ {date_mappings[-1]['new_date']}")
        logger.info("")

        response = input("å®Ÿè¡Œã—ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹? (yes/no): ")
        if response.lower() not in ['yes', 'y']:
            logger.info("å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
            return

        logger.info("")

        # å„æ—¥ä»˜ã‚’æ›´æ–°
        logger.info("ğŸ”„ trade_dateæ›´æ–°ä¸­...")
        logger.info("-" * 70)

        total_updated = 0

        for i, mapping in enumerate(date_mappings, 1):
            old_date = mapping['old_date']
            new_date = mapping['new_date']

            try:
                # è©²å½“æ—¥ä»˜ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
                count_response = supabase.table('bond_data') \
                    .select('*', count='exact') \
                    .eq('trade_date', old_date) \
                    .limit(1) \
                    .execute()

                record_count = count_response.count

                # æ›´æ–°
                update_response = supabase.table('bond_data') \
                    .update({'trade_date': new_date}) \
                    .eq('trade_date', old_date) \
                    .execute()

                total_updated += record_count

                logger.info(f"  [{i}/{len(date_mappings)}] {old_date} â†’ {new_date}: {record_count:,}ä»¶æ›´æ–°")

            except Exception as e:
                logger.error(f"  âŒ ã‚¨ãƒ©ãƒ¼: {old_date} - {e}")
                continue

        logger.info("")
        logger.info("=" * 70)
        logger.info("âœ… å‡¦ç†å®Œäº†ï¼")
        logger.info("=" * 70)
        logger.info(f"  æ›´æ–°æ—¥æ•°: {len(date_mappings)}æ—¥")
        logger.info(f"  æ›´æ–°ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_updated:,}ä»¶")
        logger.info("=" * 70)
        logger.info("")

        # æ¤œè¨¼
        logger.info("ğŸ” æ¤œè¨¼ä¸­...")
        logger.info(f"  {from_date_str} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ãªã„ã‹ç¢ºèª...")

        verify_response = supabase.table('bond_data') \
            .select('*', count='exact') \
            .gte('trade_date', from_date_str) \
            .limit(1) \
            .execute()

        remaining_count = verify_response.count

        if remaining_count > 0:
            logger.warning(f"  âš ï¸  {from_date_str} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãŒ {remaining_count}ä»¶æ®‹ã£ã¦ã„ã¾ã™")
            logger.warning(f"  ã“ã‚Œã¯é‡è¤‡ã¾ãŸã¯æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        else:
            logger.info(f"  âœ… {from_date_str} ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ­£å¸¸ï¼‰")

        logger.info("")

    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        raise


if __name__ == '__main__':
    main()
