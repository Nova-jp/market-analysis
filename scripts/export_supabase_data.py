#!/usr/bin/env python3
"""
Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

Usage:
    python scripts/export_supabase_data.py
"""
import os
import json
import requests
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv

load_dotenv()

# Supabaseè¨­å®š
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')

HEADERS = {
    'apikey': SUPABASE_KEY,
    'Authorization': f'Bearer {SUPABASE_KEY}',
    'Content-Type': 'application/json'
}

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«
TABLES = ['bond_data', 'boj_holdings', 'irs_data', 'bond_auction']

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
EXPORT_DIR = 'data_exports'
os.makedirs(EXPORT_DIR, exist_ok=True)


def get_total_count(table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
    headers = HEADERS.copy()
    headers['Prefer'] = 'count=exact'

    response = requests.head(
        f'{SUPABASE_URL}/rest/v1/{table_name}',
        headers=headers,
        timeout=30
    )

    if 'content-range' in response.headers:
        content_range = response.headers['content-range']
        parts = content_range.split('/')
        if len(parts) == 2 and parts[1] != '*':
            return int(parts[1])

    return 0


def export_table_data(table_name: str, batch_size: int = 1000) -> str:
    """
    ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    Args:
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
        batch_size: 1å›ã®ã‚¯ã‚¨ãƒªã§å–å¾—ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°

    Returns:
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    print(f"\n{'='*60}")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}")
    print(f"{'='*60}")

    # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—
    total_count = get_total_count(table_name)
    print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_count:,}")

    if total_count == 0:
        print(f"âš ï¸  {table_name} ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return None

    all_data = []
    offset = 0

    while offset < total_count:
        print(f"å–å¾—ä¸­... {offset:,} / {total_count:,} ({(offset/total_count*100):.1f}%)", end='\r')

        response = requests.get(
            f'{SUPABASE_URL}/rest/v1/{table_name}',
            params={
                'select': '*',
                'offset': offset,
                'limit': batch_size,
                'order': 'created_at.asc' if table_name != 'bond_data' else 'trade_date.asc'
            },
            headers=HEADERS,
            timeout=60
        )

        if response.status_code != 200:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
            break

        batch_data = response.json()
        if not batch_data:
            break

        all_data.extend(batch_data)
        offset += batch_size

        # æœ€å¾Œã®ãƒãƒƒãƒã®å ´åˆã¯çµ‚äº†
        if len(batch_data) < batch_size:
            break

    print(f"\nâœ… å–å¾—å®Œäº†: {len(all_data):,} ãƒ¬ã‚³ãƒ¼ãƒ‰")

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{EXPORT_DIR}/{table_name}_{timestamp}.json"

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2, default=str)

    file_size_mb = os.path.getsize(filename) / (1024 * 1024)
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {filename} ({file_size_mb:.2f} MB)")

    return filename


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*60)
    print("Supabase ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("="*60)
    print(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå…ˆ: {EXPORT_DIR}/")
    print(f"å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(TABLES)}")

    export_summary = {}

    for table_name in TABLES:
        try:
            filename = export_table_data(table_name)
            export_summary[table_name] = {
                'status': 'success' if filename else 'empty',
                'file': filename
            }
        except Exception as e:
            print(f"\nâŒ {table_name} ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            export_summary[table_name] = {
                'status': 'error',
                'error': str(e)
            }

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†ã‚µãƒãƒªãƒ¼")
    print("="*60)
    for table, info in export_summary.items():
        status_icon = {
            'success': 'âœ…',
            'empty': 'âš ï¸ ',
            'error': 'âŒ'
        }.get(info['status'], '?')
        print(f"{status_icon} {table}: {info['status']}")

    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. Cloud SQL Proxyã‚’èµ·å‹•")
    print("2. psqlã§ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ")
    print("3. scripts/import_to_cloudsql.py ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")


if __name__ == '__main__':
    main()
