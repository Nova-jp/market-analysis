#!/usr/bin/env python3
"""
bond_dataã‚’å¹´åˆ¥ã«åˆ†å‰²ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

Usage:
    python scripts/export_bond_data_by_year.py
"""
import requests
import json
import os
from datetime import datetime
from typing import List, Dict, Any

# Supabaseè¨­å®š
SUPABASE_URL = 'https://yfravzuebsvkzjnabalj.supabase.co'
SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InlmcmF2enVlYnN2a3pqbmFiYWxqIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NzEwNTQ1MCwiZXhwIjoyMDcyNjgxNDUwfQ.0-Qq9JKJ96LxKm5RGCWxZp3c9hs988sQ_0_G2-N9LAA'

HEADERS = {
    'apikey': SUPABASE_KEY,
    'Authorization': f'Bearer {SUPABASE_KEY}',
    'Content-Type': 'application/json'
}

EXPORT_DIR = 'data_exports/bond_data_by_year'
os.makedirs(EXPORT_DIR, exist_ok=True)


def export_year_data(year: int, batch_size: int = 1000) -> int:
    """
    ç‰¹å®šå¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

    Args:
        year: å¯¾è±¡å¹´
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º

    Returns:
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    """
    print(f"\n{'='*60}")
    print(f"å¹´: {year}")
    print(f"{'='*60}")

    start_date = f"{year}-01-01"
    end_date = f"{year}-12-31"

    all_data = []
    offset = 0

    while True:
        print(f"å–å¾—ä¸­... offset={offset:,}", end='\r')

        try:
            response = requests.get(
                f'{SUPABASE_URL}/rest/v1/bond_data',
                params={
                    'select': '*',
                    'trade_date': f'gte.{start_date}',
                    'trade_date': f'lte.{end_date}',
                    'order': 'trade_date.asc',
                    'offset': offset,
                    'limit': batch_size
                },
                headers=HEADERS,
                timeout=60
            )

            if response.status_code != 200:
                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                break

            batch_data = response.json()

            if not batch_data:
                break

            all_data.extend(batch_data)
            offset += batch_size

            # æœ€å¾Œã®ãƒãƒƒãƒã®å ´åˆã¯çµ‚äº†
            if len(batch_data) < batch_size:
                break

        except requests.exceptions.Timeout:
            print(f"\nâš ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿ (offset={offset}). 5ç§’å¾…æ©Ÿå¾Œãƒªãƒˆãƒ©ã‚¤...")
            import time
            time.sleep(5)
            continue
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
            break

    total_count = len(all_data)
    print(f"\nâœ… å–å¾—å®Œäº†: {total_count:,} ãƒ¬ã‚³ãƒ¼ãƒ‰")

    if total_count == 0:
        return 0

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    filename = f"{EXPORT_DIR}/bond_data_{year}.json"

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2, default=str)

    file_size_mb = os.path.getsize(filename) / (1024 * 1024)
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {filename} ({file_size_mb:.2f} MB)")

    return total_count


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*60)
    print("bond_data å¹´åˆ¥ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("="*60)
    print(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå…ˆ: {EXPORT_DIR}/")

    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã‚’ç¢ºèª
    print("\nãƒ‡ãƒ¼ã‚¿ç¯„å›²ç¢ºèªä¸­...")

    # æœ€å¤ã®å¹´ã‚’å–å¾—
    resp = requests.get(
        f'{SUPABASE_URL}/rest/v1/bond_data',
        params={'select': 'trade_date', 'order': 'trade_date.asc', 'limit': 1},
        headers=HEADERS
    )

    if resp.status_code == 200 and resp.json():
        min_date = resp.json()[0]['trade_date']
        min_year = int(min_date.split('-')[0])
        print(f"æœ€å¤æ—¥ä»˜: {min_date} (å¹´: {min_year})")
    else:
        min_year = 2002
        print(f"æœ€å¤æ—¥ä»˜å–å¾—å¤±æ•—ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¹´: {min_year}")

    # æœ€æ–°ã®å¹´ã‚’å–å¾—
    resp = requests.get(
        f'{SUPABASE_URL}/rest/v1/bond_data',
        params={'select': 'trade_date', 'order': 'trade_date.desc', 'limit': 1},
        headers=HEADERS
    )

    if resp.status_code == 200 and resp.json():
        max_date = resp.json()[0]['trade_date']
        max_year = int(max_date.split('-')[0])
        print(f"æœ€æ–°æ—¥ä»˜: {max_date} (å¹´: {max_year})")
    else:
        max_year = 2025
        print(f"æœ€æ–°æ—¥ä»˜å–å¾—å¤±æ•—ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¹´: {max_year}")

    # å¹´ã”ã¨ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    total_records = 0
    export_summary = {}

    for year in range(min_year, max_year + 1):
        try:
            count = export_year_data(year)
            export_summary[year] = {'status': 'success', 'count': count}
            total_records += count
        except Exception as e:
            print(f"\nâŒ {year}å¹´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            export_summary[year] = {'status': 'error', 'error': str(e)}

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†ã‚µãƒãƒªãƒ¼")
    print("="*60)
    for year, info in export_summary.items():
        status_icon = 'âœ…' if info['status'] == 'success' else 'âŒ'
        count = info.get('count', 0)
        print(f"{status_icon} {year}å¹´: {count:,} ãƒ¬ã‚³ãƒ¼ãƒ‰")

    print(f"\nç·ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ•°: {total_records:,} ãƒ¬ã‚³ãƒ¼ãƒ‰")
    print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"python scripts/import_bond_data_to_cloudsql.py")


if __name__ == '__main__':
    main()
