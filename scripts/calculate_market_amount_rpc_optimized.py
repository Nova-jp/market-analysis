#!/usr/bin/env python3
"""
å¸‚ä¸­æ®‹å­˜é¡ï¼ˆmarket_amountï¼‰è¶…é«˜é€Ÿè¨ˆç®—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆRPCç‰ˆ - æœ€é©åŒ–ï¼‰

æˆ¦ç•¥:
1. market_amount IS NULL ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿å–å¾—ï¼ˆæœªå‡¦ç†åˆ†ã®ã¿ï¼‰
2. ãƒ¡ãƒ¢ãƒªå†…ã§å…¨market_amountã‚’è¨ˆç®—ï¼ˆO(N)ï¼‰
3. Supabase RPCé–¢æ•°ã§ä¸€æ‹¬UPDATEï¼ˆ1000ä»¶ãšã¤ãƒãƒƒãƒï¼‰

å‡¦ç†æ™‚é–“: 3-5åˆ†ï¼ˆæœªå‡¦ç†åˆ†ã®ã¿ï¼‰

å‰ææ¡ä»¶:
Supabaseã«ä»¥ä¸‹ã®RPCé–¢æ•°ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨:

CREATE OR REPLACE FUNCTION update_market_amounts(
    updates jsonb
) RETURNS int AS $$
DECLARE
    update_count int := 0;
    rows_affected int;
    item jsonb;
BEGIN
    FOR item IN SELECT * FROM jsonb_array_elements(updates)
    LOOP
        UPDATE bond_data
        SET market_amount = (item->>'market_amount')::bigint
        WHERE bond_code = item->>'bond_code'
          AND trade_date = (item->>'trade_date')::date;

        GET DIAGNOSTICS rows_affected = ROW_COUNT;
        update_count := update_count + rows_affected;
    END LOOP;

    RETURN update_count;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
"""

import sys
import os
from datetime import datetime
from typing import Dict, List, Tuple, Set
from collections import defaultdict
from bisect import bisect_right
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from supabase import create_client

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class RPCMarketAmountCalculatorOptimized:
    """RPCé–¢æ•°ã‚’ä½¿ã£ãŸè¶…é«˜é€Ÿå¸‚ä¸­æ®‹å­˜é¡è¨ˆç®—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""

    def __init__(self):
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        if not url or not key:
            raise ValueError("SUPABASE_URL and SUPABASE_KEY must be set")
        self.supabase = create_client(url, key)

    def get_unprocessed_bond_codes(self) -> Set[str]:
        """å…¨éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆDISTINCTä½¿ç”¨ï¼‰"""
        logger.info("  ğŸ“‹ å…¨éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­ï¼ˆDISTINCT bond_codeä½¿ç”¨ï¼‰...")

        bond_codes = set()
        offset = 0
        limit = 1000

        # DISTINCT bond_codeã§éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—ï¼ˆè»½é‡ï¼‰
        while True:
            try:
                response = self.supabase.table('bond_data') \
                    .select('bond_code') \
                    .range(offset, offset + limit - 1) \
                    .execute()

                if not response.data:
                    break

                for record in response.data:
                    bond_codes.add(record['bond_code'])

                if len(response.data) < limit:
                    break

                offset += limit

                if offset % 50000 == 0:
                    logger.info(f"    é€²æ—: {offset:,}ä»¶ã‚¹ã‚­ãƒ£ãƒ³æ¸ˆã¿ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯: {len(bond_codes):,}éŠ˜æŸ„ï¼‰")

            except Exception as e:
                logger.error(f"    âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆoffset={offset}ï¼‰: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ—¢ã«å–å¾—ã—ãŸéŠ˜æŸ„ã§ç¶™ç¶š
                break

        logger.info(f"  âœ… å…¨éŠ˜æŸ„å–å¾—å®Œäº†: {len(bond_codes):,}éŠ˜æŸ„")
        return bond_codes

    def fetch_unprocessed_trades(self, bond_codes: Set[str]) -> List[Dict]:
        """æœªå‡¦ç†éŠ˜æŸ„ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—"""
        logger.info(f"  ğŸ“¥ æœªå‡¦ç†å–å¼•ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ï¼ˆ{len(bond_codes)}éŠ˜æŸ„ï¼‰...")

        all_data = []
        bond_codes_list = sorted(list(bond_codes))

        # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’100å€‹ãšã¤ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å–å¾—
        chunk_size = 100
        for i in range(0, len(bond_codes_list), chunk_size):
            chunk = bond_codes_list[i:i+chunk_size]
            offset = 0
            limit = 1000

            while True:
                response = self.supabase.table('bond_data') \
                    .select('bond_code, trade_date') \
                    .in_('bond_code', chunk) \
                    .range(offset, offset + limit - 1) \
                    .execute()

                if not response.data:
                    break

                all_data.extend(response.data)

                if len(response.data) < limit:
                    break

                offset += limit

            if (i + chunk_size) % 500 == 0:
                logger.info(f"    é€²æ—: {i + chunk_size}/{len(bond_codes_list)}éŠ˜æŸ„å‡¦ç†æ¸ˆã¿ï¼ˆ{len(all_data):,}ä»¶ï¼‰")

        logger.info(f"  âœ… å–å¼•ãƒ‡ãƒ¼ã‚¿: {len(all_data):,}ä»¶å–å¾—å®Œäº†")
        return all_data

    def fetch_all_simple(self, table_name: str, columns: str) -> List[Dict]:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ãƒ¼ãƒ–ãƒ«å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆbond_auction, boj_holdingsç”¨ï¼‰"""
        logger.info(f"  ğŸ“¥ {table_name} ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        all_data = []
        offset = 0
        limit = 1000

        while True:
            response = self.supabase.table(table_name) \
                .select(columns) \
                .range(offset, offset + limit - 1) \
                .execute()

            if not response.data:
                break

            all_data.extend(response.data)

            if len(response.data) < limit:
                break

            offset += limit

            if offset % 10000 == 0:
                logger.info(f"    é€²æ—: {offset:,}ä»¶å–å¾—æ¸ˆã¿...")

        logger.info(f"  âœ… {table_name}: {len(all_data):,}ä»¶å–å¾—å®Œäº†")
        return all_data

    def calculate_all_market_amounts(self) -> List[Dict]:
        """
        æœªå‡¦ç†åˆ†ã®market_amountã‚’è¨ˆç®—

        Returns:
            [{'bond_code': str, 'trade_date': str, 'market_amount': int}, ...]
        """
        logger.info("=" * 70)
        logger.info("Step 1: æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ç‰¹å®š")
        logger.info("=" * 70)

        # æœªå‡¦ç†éŠ˜æŸ„ã‚’ç‰¹å®š
        unprocessed_bonds = self.get_unprocessed_bond_codes()

        if not unprocessed_bonds:
            logger.info("âœ… ã™ã¹ã¦å‡¦ç†æ¸ˆã¿ã§ã™ï¼")
            return []

        logger.info("")
        logger.info("=" * 70)
        logger.info("Step 2: ãƒ‡ãƒ¼ã‚¿å–å¾—")
        logger.info("=" * 70)

        # æœªå‡¦ç†éŠ˜æŸ„ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—
        trade_data = self.fetch_unprocessed_trades(unprocessed_bonds)

        # ç™ºè¡Œãƒ»æ—¥éŠ€ãƒ‡ãƒ¼ã‚¿ã¯å…¨ä»¶å–å¾—ï¼ˆã‚µã‚¤ã‚ºãŒå°ã•ã„ãŸã‚ï¼‰
        auction_data = self.fetch_all_simple(
            'bond_auction',
            'bond_code, auction_date, allocated_amount'
        )
        boj_data = self.fetch_all_simple(
            'boj_holdings',
            'bond_code, data_date, face_value'
        )

        logger.info("")
        logger.info("=" * 70)
        logger.info("Step 3: ãƒ‡ãƒ¼ã‚¿æ•´ç†")
        logger.info("=" * 70)

        # éŠ˜æŸ„ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        auction_by_bond = defaultdict(list)
        for row in auction_data:
            auction_by_bond[row['bond_code']].append(
                (row['auction_date'], row.get('allocated_amount', 0) or 0)
            )

        for bond_code in auction_by_bond:
            auction_by_bond[bond_code].sort(key=lambda x: x[0])

        boj_by_bond = defaultdict(list)
        for row in boj_data:
            boj_by_bond[row['bond_code']].append(
                (row['data_date'], row.get('face_value', 0) or 0)
            )

        for bond_code in boj_by_bond:
            boj_by_bond[bond_code].sort(key=lambda x: x[0])

        trades_by_bond = defaultdict(list)
        for row in trade_data:
            trades_by_bond[row['bond_code']].append(row['trade_date'])

        for bond_code in trades_by_bond:
            trades_by_bond[bond_code].sort()

        logger.info(f"  æœªå‡¦ç†éŠ˜æŸ„æ•°: {len(trades_by_bond):,}")
        logger.info(f"  æœªå‡¦ç†å–å¼•æ—¥æ•°: {sum(len(v) for v in trades_by_bond.values()):,}")

        logger.info("")
        logger.info("=" * 70)
        logger.info("Step 4: market_amountè¨ˆç®—")
        logger.info("=" * 70)

        results = []
        total_bonds = len(trades_by_bond)
        processed = 0

        for bond_code, trade_dates in trades_by_bond.items():
            auctions = auction_by_bond.get(bond_code, [])
            boj_holdings = boj_by_bond.get(bond_code, [])

            cumulative_issuance = 0
            auction_idx = 0

            for trade_date in trade_dates:
                # ãã®æ—¥ã¾ã§ã®ç´¯ç©ç™ºè¡Œé¡
                while auction_idx < len(auctions) and auctions[auction_idx][0] <= trade_date:
                    cumulative_issuance += int(auctions[auction_idx][1])
                    auction_idx += 1

                # ãã®æ—¥æ™‚ç‚¹ã®æ—¥éŠ€ä¿æœ‰é¡ï¼ˆäºŒåˆ†æ¢ç´¢ï¼‰
                boj_holding = 0
                if boj_holdings:
                    dates = [h[0] for h in boj_holdings]
                    idx = bisect_right(dates, trade_date) - 1
                    if idx >= 0:
                        boj_holding = int(boj_holdings[idx][1])

                # å¸‚ä¸­æ®‹å­˜é¡
                market_amount = cumulative_issuance - boj_holding

                results.append({
                    'bond_code': bond_code,
                    'trade_date': trade_date,
                    'market_amount': market_amount
                })

            processed += 1
            if processed % 20 == 0:
                logger.info(f"  é€²æ—: {processed}/{total_bonds} éŠ˜æŸ„ ({len(results):,}ä»¶è¨ˆç®—æ¸ˆã¿)")

        logger.info(f"  âœ… è¨ˆç®—å®Œäº†: {len(results):,}ä»¶")
        return results

    def bulk_update_via_rpc(self, results: List[Dict], batch_size: int = 1000) -> int:
        """
        RPCé–¢æ•°ã‚’ä½¿ã£ã¦ä¸€æ‹¬UPDATE

        Args:
            results: [{'bond_code': str, 'trade_date': str, 'market_amount': int}, ...]
            batch_size: 1å›ã®RPCå‘¼ã³å‡ºã—ã§å‡¦ç†ã™ã‚‹ä»¶æ•°

        Returns:
            æ›´æ–°ä»¶æ•°
        """
        logger.info("")
        logger.info("=" * 70)
        logger.info("Step 5: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ï¼ˆRPCé–¢æ•°ä½¿ç”¨ï¼‰")
        logger.info("=" * 70)

        total_updated = 0
        total_batches = (len(results) + batch_size - 1) // batch_size

        for i in range(0, len(results), batch_size):
            batch = results[i:i + batch_size]
            batch_num = i // batch_size + 1

            try:
                # RPCé–¢æ•°å‘¼ã³å‡ºã—
                response = self.supabase.rpc('update_market_amounts', {
                    'updates': batch
                }).execute()

                updated_count = response.data if response.data else 0
                total_updated += updated_count

                logger.info(
                    f"  ãƒãƒƒãƒ {batch_num}/{total_batches}: "
                    f"{updated_count:,}ä»¶æ›´æ–° (ç´¯è¨ˆ: {total_updated:,}ä»¶)"
                )

            except Exception as e:
                logger.error(f"  âŒ ãƒãƒƒãƒ {batch_num} æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"     ãƒãƒƒãƒç¯„å›²: {i} - {i + len(batch)}")
                # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ç¶šè¡Œ
                continue

        logger.info(f"  âœ… å…¨ãƒãƒƒãƒå®Œäº†: {total_updated:,}ä»¶æ›´æ–°")
        return total_updated

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        start_time = datetime.now()

        logger.info("=" * 70)
        logger.info("å¸‚ä¸­æ®‹å­˜é¡ï¼ˆmarket_amountï¼‰è¶…é«˜é€Ÿè¨ˆç®— - RPCç‰ˆï¼ˆæœ€é©åŒ–ï¼‰")
        logger.info("=" * 70)
        logger.info("")

        try:
            # Step 1-4: æœªå‡¦ç†ç‰¹å®š â†’ ãƒ‡ãƒ¼ã‚¿å–å¾— â†’ æ•´ç† â†’ è¨ˆç®—
            results = self.calculate_all_market_amounts()

            if not results:
                logger.info("å‡¦ç†å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
                return 0

            # Step 5: RPCé–¢æ•°ã§ä¸€æ‹¬UPDATE
            updated = self.bulk_update_via_rpc(results)

            # å®Œäº†
            elapsed = (datetime.now() - start_time).total_seconds()

            logger.info("")
            logger.info("=" * 70)
            logger.info("âœ… å‡¦ç†å®Œäº†")
            logger.info("=" * 70)
            logger.info(f"è¨ˆç®—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(results):,}ä»¶")
            logger.info(f"æ›´æ–°ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {updated:,}ä»¶")
            logger.info(f"å‡¦ç†æ™‚é–“: {elapsed/60:.1f}åˆ† ({elapsed:.0f}ç§’)")
            if elapsed > 0:
                logger.info(f"å‡¦ç†é€Ÿåº¦: {updated/elapsed:.0f}ä»¶/ç§’")
            logger.info("=" * 70)

            return updated

        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
            raise


def verify_rpc_function_exists(supabase):
    """RPCé–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª"""
    try:
        # ç©ºé…åˆ—ã§ãƒ†ã‚¹ãƒˆå‘¼ã³å‡ºã—
        response = supabase.rpc('update_market_amounts', {'updates': []}).execute()
        logger.info("âœ… RPCé–¢æ•° 'update_market_amounts' ãŒå­˜åœ¨ã—ã¾ã™")
        return True
    except Exception as e:
        logger.error("âŒ RPCé–¢æ•° 'update_market_amounts' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        logger.error(f"   ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error("")
        logger.error("=" * 70)
        logger.error("scripts/create_rpc_function.sql ã‚’å‚ç…§ã—ã¦ãã ã•ã„")
        logger.error("=" * 70)
        return False


def main():
    url = os.getenv('SUPABASE_URL')
    key = os.getenv('SUPABASE_KEY')
    supabase = create_client(url, key)

    # RPCé–¢æ•°ã®å­˜åœ¨ç¢ºèª
    if not verify_rpc_function_exists(supabase):
        logger.error("")
        logger.error("RPCé–¢æ•°ã‚’ä½œæˆã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # è¨ˆç®—å®Ÿè¡Œ
    calculator = RPCMarketAmountCalculatorOptimized()
    calculator.run()


if __name__ == '__main__':
    main()
