{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ä¸»æˆåˆ†åˆ†æï¼ˆæœ€æ–°100å–¶æ¥­æ—¥ï¼‰\n",
    "\n",
    "## æ¦‚è¦\n",
    "æ—¥æœ¬å›½å‚µã®ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## åˆ†ææ‰‹é †\n",
    "1. æœ€æ–°æ—¥ã‹ã‚‰éå»100å–¶æ¥­æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "2. å…¨æ—¥ä»˜ã®æ®‹å­˜æœŸé–“ã®å’Œé›†åˆã‚’ä½œæˆï¼ˆ0.5å¹´æœªæº€ã‚’é™¤å¤–ï¼‰\n",
    "3. 3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§æ¬ æå€¤ã‚’è£œå®Œ\n",
    "4. ä¸»æˆåˆ†åˆ†æã‚’å®Ÿè¡Œ\n",
    "5. çµæœã‚’å¯è¦–åŒ–ãƒ»è§£é‡ˆ\n",
    "\n",
    "## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "- **åˆ†ææœŸé–“**: æœ€æ–°100å–¶æ¥­æ—¥\n",
    "- **æ®‹å­˜æœŸé–“é–¾å€¤**: 0.5å¹´ä»¥ä¸Š\n",
    "- **è£œé–“æ–¹æ³•**: 3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿\n",
    "load_dotenv(os.path.join(project_root, '.env'))\n",
    "\n",
    "# Supabaseè¨­å®š\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "SUPABASE_KEY = os.getenv('SUPABASE_KEY')\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•è¨­å®š\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('âœ… ç’°å¢ƒè¨­å®šå®Œäº†')\n",
    "print(f'Supabase URL: {SUPABASE_URL[:40]}...' if SUPABASE_URL else 'âŒ SUPABASE_URL not set')\n",
    "print(f'Supabase Key: {SUPABASE_KEY[:20]}...' if SUPABASE_KEY else 'âŒ SUPABASE_KEY not set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_dates(limit=200):\n",
    "    \"\"\"\n",
    "    æœ€æ–°ã®å–¶æ¥­æ—¥ã‚’å–å¾—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    limit : int\n",
    "        å–å¾—ã™ã‚‹æ—¥ä»˜æ•°ï¼ˆ100å–¶æ¥­æ—¥ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : æ—¥ä»˜ãƒªã‚¹ãƒˆï¼ˆé™é †ï¼‰\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'apikey': SUPABASE_KEY,\n",
    "        'Authorization': f'Bearer {SUPABASE_KEY}'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        f'{SUPABASE_URL}/rest/v1/bond_data',\n",
    "        params={\n",
    "            'select': 'trade_date',\n",
    "            'order': 'trade_date.desc',\n",
    "            'limit': limit * 10  # ãƒ‡ãƒ¼ã‚¿ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãŸã‚å¤šã‚ã«å–å¾—\n",
    "        },\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code}')\n",
    "    \n",
    "    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ—¥ä»˜ã‚’æŠ½å‡ºã—ã¦ã‚½ãƒ¼ãƒˆ\n",
    "    dates = sorted(list(set([row['trade_date'] for row in response.json()])), reverse=True)\n",
    "    \n",
    "    return dates[:limit]\n",
    "\n",
    "\n",
    "def get_yield_data_for_date(date):\n",
    "    \"\"\"\n",
    "    æŒ‡å®šæ—¥ã®ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    date : str\n",
    "        å–å¾—æ—¥ä»˜ï¼ˆYYYY-MM-DDï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : ã‚«ãƒ©ãƒ  [maturity_years, yield_rate]\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'apikey': SUPABASE_KEY,\n",
    "        'Authorization': f'Bearer {SUPABASE_KEY}'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        f'{SUPABASE_URL}/rest/v1/bond_data',\n",
    "        params={\n",
    "            'select': 'trade_date,due_date,ave_compound_yield',\n",
    "            'trade_date': f'eq.{date}',\n",
    "            'ave_compound_yield': 'not.is.null',\n",
    "            'due_date': 'not.is.null'\n",
    "        },\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200 or not response.json():\n",
    "        return pd.DataFrame(columns=['maturity_years', 'yield_rate'])\n",
    "    \n",
    "    # æ®‹å­˜å¹´æ•°ã‚’è¨ˆç®—\n",
    "    data_list = []\n",
    "    for row in response.json():\n",
    "        try:\n",
    "            trade_dt = datetime.strptime(row['trade_date'], '%Y-%m-%d')\n",
    "            due_dt = datetime.strptime(row['due_date'], '%Y-%m-%d')\n",
    "            maturity_years = (due_dt - trade_dt).days / 365.25\n",
    "            \n",
    "            # 0.5å¹´ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã®ã¿\n",
    "            if maturity_years >= 0.5 and row['ave_compound_yield'] is not None:\n",
    "                data_list.append({\n",
    "                    'maturity_years': round(maturity_years, 4),\n",
    "                    'yield_rate': float(row['ave_compound_yield'])\n",
    "                })\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "print('âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€æ–°ã®å–¶æ¥­æ—¥ã‚’å–å¾—\n",
    "print('ğŸ“… å–¶æ¥­æ—¥å–å¾—ä¸­...')\n",
    "available_dates = get_latest_dates(limit=200)\n",
    "target_dates = available_dates[:100]  # æœ€æ–°100å–¶æ¥­æ—¥\n",
    "\n",
    "print(f'âœ… åˆ†æå¯¾è±¡æ—¥ä»˜: {len(target_dates)}æ—¥')\n",
    "print(f'   æœŸé–“: {target_dates[-1]} ~ {target_dates[0]}')\n",
    "print(f'   æœ€æ–°æ—¥: {target_dates[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "print('\\nğŸ“Š ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...')\n",
    "daily_data = {}\n",
    "\n",
    "for i, date in enumerate(target_dates, 1):\n",
    "    df = get_yield_data_for_date(date)\n",
    "    if not df.empty:\n",
    "        daily_data[date] = df\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f'   é€²æ—: {i}/{len(target_dates)}æ—¥')\n",
    "\n",
    "print(f'\\nâœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(daily_data)}æ—¥åˆ†')\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ\n",
    "total_points = sum(len(df) for df in daily_data.values())\n",
    "avg_points = total_points / len(daily_data) if daily_data else 0\n",
    "\n",
    "print(f'   ç·ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {total_points:,}å€‹')\n",
    "print(f'   1æ—¥ã‚ãŸã‚Šå¹³å‡: {avg_points:.1f}å€‹')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ®‹å­˜æœŸé–“ã®å’Œé›†åˆä½œæˆã¨ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maturity_union(daily_data):\n",
    "    \"\"\"\n",
    "    å…¨æ—¥ä»˜ã®æ®‹å­˜æœŸé–“ã®å’Œé›†åˆã‚’ä½œæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    daily_data : dict\n",
    "        æ—¥ä»˜ã”ã¨ã®DataFrameè¾æ›¸\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray : ã‚½ãƒ¼ãƒˆæ¸ˆã¿æ®‹å­˜æœŸé–“é…åˆ—\n",
    "    \"\"\"\n",
    "    all_maturities = set()\n",
    "    \n",
    "    for df in daily_data.values():\n",
    "        all_maturities.update(df['maturity_years'].values)\n",
    "    \n",
    "    return np.sort(np.array(list(all_maturities)))\n",
    "\n",
    "\n",
    "def interpolate_yields(df, common_grid):\n",
    "    \"\"\"\n",
    "    3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§å…±é€šå¹´é™è»¸ä¸Šã®åˆ©å›ã‚Šã‚’æ¨å®š\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        ã‚ã‚‹æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿\n",
    "    common_grid : np.ndarray\n",
    "        å…±é€šæ®‹å­˜æœŸé–“è»¸\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray : è£œé–“å¾Œã®åˆ©å›ã‚Šé…åˆ—\n",
    "    \"\"\"\n",
    "    if df.empty or len(df) < 2:\n",
    "        return np.full(len(common_grid), np.nan)\n",
    "    \n",
    "    # é‡è¤‡å‰Šé™¤ãƒ»ã‚½ãƒ¼ãƒˆ\n",
    "    df_sorted = df.sort_values('maturity_years').drop_duplicates('maturity_years')\n",
    "    \n",
    "    if len(df_sorted) < 2:\n",
    "        return np.full(len(common_grid), np.nan)\n",
    "    \n",
    "    # 3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“\n",
    "    cs = CubicSpline(\n",
    "        df_sorted['maturity_years'].values,\n",
    "        df_sorted['yield_rate'].values,\n",
    "        extrapolate=False  # å¤–æŒ¿ãªã—\n",
    "    )\n",
    "    \n",
    "    return cs(common_grid)\n",
    "\n",
    "\n",
    "print('âœ… ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“é–¢æ•°å®šç¾©å®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ®‹å­˜æœŸé–“ã®å’Œé›†åˆã‚’ä½œæˆ\n",
    "print('\\nğŸ”— æ®‹å­˜æœŸé–“ã®å’Œé›†åˆä½œæˆä¸­...')\n",
    "common_maturities = create_maturity_union(daily_data)\n",
    "\n",
    "print(f'âœ… å…±é€šæ®‹å­˜æœŸé–“è»¸: {len(common_maturities)}å€‹')\n",
    "print(f'   ç¯„å›²: {common_maturities.min():.2f}å¹´ ~ {common_maturities.max():.2f}å¹´')\n",
    "\n",
    "# åˆ†å¸ƒç¢ºèª\n",
    "short_term = np.sum(common_maturities <= 2)\n",
    "medium_term = np.sum((common_maturities > 2) & (common_maturities <= 10))\n",
    "long_term = np.sum(common_maturities > 10)\n",
    "\n",
    "print(f'\\n   æœŸé–“åˆ¥åˆ†å¸ƒ:')\n",
    "print(f'     çŸ­æœŸï¼ˆâ‰¤2å¹´ï¼‰: {short_term}å€‹')\n",
    "print(f'     ä¸­æœŸï¼ˆ2-10å¹´ï¼‰: {medium_term}å€‹')\n",
    "print(f'     é•·æœŸï¼ˆ>10å¹´ï¼‰: {long_term}å€‹')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ã‚’ä½œæˆ\n",
    "print('\\nğŸ”„ ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“å®Ÿè¡Œä¸­...')\n",
    "\n",
    "interpolated_data = []\n",
    "valid_dates = []\n",
    "\n",
    "for i, (date, df) in enumerate(daily_data.items(), 1):\n",
    "    interpolated = interpolate_yields(df, common_maturities)\n",
    "    \n",
    "    # NaNãŒ50%æœªæº€ã®è¡Œã®ã¿æ¡ç”¨\n",
    "    nan_ratio = np.isnan(interpolated).sum() / len(interpolated)\n",
    "    if nan_ratio < 0.5:\n",
    "        interpolated_data.append(interpolated)\n",
    "        valid_dates.append(date)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f'   é€²æ—: {i}/{len(daily_data)}æ—¥')\n",
    "\n",
    "# NumPyé…åˆ—ã«å¤‰æ›\n",
    "X = np.array(interpolated_data)\n",
    "\n",
    "print(f'\\nâœ… ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“å®Œäº†')\n",
    "print(f'   æœ‰åŠ¹æ—¥æ•°: {len(valid_dates)}æ—¥')\n",
    "print(f'   ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ã‚µã‚¤ã‚º: {X.shape}ï¼ˆæ—¥æ•° x æ®‹å­˜æœŸé–“ï¼‰')\n",
    "print(f'   NaNå«æœ‰ç‡: {np.isnan(X).sum() / X.size * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNã‚’åˆ—å¹³å‡ã§è£œå®Œ\n",
    "print('\\nğŸ”§ NaNè£œå®Œä¸­...')\n",
    "X_filled = X.copy()\n",
    "col_means = np.nanmean(X, axis=0)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    mask = np.isnan(X_filled[:, i])\n",
    "    X_filled[mask, i] = col_means[i]\n",
    "\n",
    "print(f'âœ… NaNè£œå®Œå®Œäº†')\n",
    "print(f'   è£œå®Œå¾Œã®NaNæ•°: {np.isnan(X_filled).sum()}å€‹ï¼ˆ0ã§ã‚ã‚‹ã¹ãï¼‰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–\n",
    "print('\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ä¸­...')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_filled)\n",
    "\n",
    "print(f'âœ… æ¨™æº–åŒ–å®Œäº†')\n",
    "print(f'   å¹³å‡: {X_scaled.mean():.6f} (â‰ˆ0)')\n",
    "print(f'   æ¨™æº–åå·®: {X_scaled.std():.6f} (â‰ˆ1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAå®Ÿè¡Œ\n",
    "print('\\nğŸ¯ ä¸»æˆåˆ†åˆ†æå®Ÿè¡Œä¸­...')\n",
    "n_components = min(10, X_scaled.shape[0], X_scaled.shape[1])  # æœ€å¤§10ä¸»æˆåˆ†\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f'âœ… PCAå®Œäº†')\n",
    "print(f'   ä¸»æˆåˆ†æ•°: {pca.n_components_}å€‹')\n",
    "print(f'   å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X_pca.shape}')\n",
    "print(f'\\nğŸ“ˆ å¯„ä¸ç‡:')\n",
    "for i, ratio in enumerate(pca.explained_variance_ratio_[:5], 1):\n",
    "    print(f'   PC{i}: {ratio*100:.2f}%')\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(f'\\nğŸ“Š ç´¯ç©å¯„ä¸ç‡:')\n",
    "print(f'   PC1-3: {cumsum[2]*100:.2f}%')\n",
    "print(f'   PC1-5: {cumsum[4]*100:.2f}%' if len(cumsum) >= 5 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. çµæœã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å¯„ä¸ç‡ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# å€‹åˆ¥å¯„ä¸ç‡\n",
    "axes[0].bar(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "            pca.explained_variance_ratio_ * 100,\n",
    "            alpha=0.7,\n",
    "            color='steelblue')\n",
    "axes[0].set_xlabel('ä¸»æˆåˆ†', fontsize=12)\n",
    "axes[0].set_ylabel('å¯„ä¸ç‡ (%)', fontsize=12)\n",
    "axes[0].set_title('ä¸»æˆåˆ†ã”ã¨ã®å¯„ä¸ç‡', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ç´¯ç©å¯„ä¸ç‡\n",
    "axes[1].plot(range(1, len(cumsum) + 1), \n",
    "             cumsum * 100, \n",
    "             marker='o', \n",
    "             linewidth=2,\n",
    "             markersize=8,\n",
    "             color='darkred')\n",
    "axes[1].axhline(y=90, color='gray', linestyle='--', linewidth=1, alpha=0.7, label='90%')\n",
    "axes[1].axhline(y=95, color='gray', linestyle='--', linewidth=1, alpha=0.7, label='95%')\n",
    "axes[1].set_xlabel('ä¸»æˆåˆ†æ•°', fontsize=12)\n",
    "axes[1].set_ylabel('ç´¯ç©å¯„ä¸ç‡ (%)', fontsize=12)\n",
    "axes[1].set_title('ç´¯ç©å¯„ä¸ç‡', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('âœ… å¯„ä¸ç‡ã‚°ãƒ©ãƒ•è¡¨ç¤ºå®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ä¸»æˆåˆ†ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "labels = ['PC1ï¼ˆæ°´æº–å¤‰å‹•ï¼‰', 'PC2ï¼ˆå‚¾ãå¤‰å‹•ï¼‰', 'PC3ï¼ˆæ›²ç‡å¤‰å‹•ï¼‰']\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].plot(common_maturities, \n",
    "                 pca.components_[i], \n",
    "                 linewidth=2.5,\n",
    "                 color=colors[i],\n",
    "                 label=labels[i])\n",
    "    axes[i].axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    axes[i].set_xlabel('æ®‹å­˜æœŸé–“ï¼ˆå¹´ï¼‰', fontsize=12)\n",
    "    axes[i].set_ylabel('å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«', fontsize=12)\n",
    "    axes[i].set_title(f'{labels[i]} - å¯„ä¸ç‡: {pca.explained_variance_ratio_[i]*100:.2f}%', \n",
    "                      fontsize=13, \n",
    "                      fontweight='bold')\n",
    "    axes[i].legend(loc='best', fontsize=11)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('âœ… ä¸»æˆåˆ†ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¤ºå®Œäº†')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã®æ™‚ç³»åˆ—å¤‰åŒ–\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 10))\n",
    "\n",
    "# æ—¥ä»˜ã‚’datetimeã«å¤‰æ›\n",
    "date_objects = [datetime.strptime(d, '%Y-%m-%d') for d in valid_dates]\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].plot(date_objects, \n",
    "                 X_pca[:, i], \n",
    "                 linewidth=2,\n",
    "                 color=colors[i],\n",
    "                 alpha=0.8)\n",
    "    axes[i].axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    axes[i].set_ylabel(f'PC{i+1} ã‚¹ã‚³ã‚¢', fontsize=12)\n",
    "    axes[i].set_title(f'{labels[i]}ã®æ™‚ç³»åˆ—å¤‰åŒ–', fontsize=13, fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # xè»¸ã‚’å›è»¢\n",
    "    plt.setp(axes[i].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "axes[-1].set_xlabel('æ—¥ä»˜', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('âœ… ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•è¡¨ç¤ºå®Œäº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. çµæœã®è§£é‡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('ğŸ“‹ ä¸»æˆåˆ†åˆ†æçµæœã‚µãƒãƒªãƒ¼')\n",
    "print('=' * 70)\n",
    "print(f'åˆ†ææœŸé–“: {valid_dates[-1]} ~ {valid_dates[0]}')\n",
    "print(f'æ—¥æ•°: {len(valid_dates)}æ—¥')\n",
    "print(f'æ®‹å­˜æœŸé–“è»¸: {len(common_maturities)}å€‹ï¼ˆ{common_maturities.min():.2f}å¹´ ~ {common_maturities.max():.2f}å¹´ï¼‰')\n",
    "print()\n",
    "print('ä¸»æˆåˆ†ã®å¯„ä¸ç‡:')\n",
    "for i in range(min(5, len(pca.explained_variance_ratio_))):\n",
    "    print(f'  PC{i+1}: {pca.explained_variance_ratio_[i]*100:.2f}% ï¼ˆç´¯ç©: {cumsum[i]*100:.2f}%ï¼‰')\n",
    "print()\n",
    "print('=' * 70)\n",
    "print('ğŸ’¡ è§£é‡ˆ')\n",
    "print('=' * 70)\n",
    "print('PC1ï¼ˆç¬¬1ä¸»æˆåˆ†ï¼‰: ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ã®æ°´æº–å¤‰å‹•ï¼ˆãƒ‘ãƒ©ãƒ¬ãƒ«ã‚·ãƒ•ãƒˆï¼‰')\n",
    "print('  â†’ å…¨æœŸé–“ã®é‡‘åˆ©ãŒä¸€æ–‰ã«ä¸Šä¸‹ã™ã‚‹å‹•ã')\n",
    "print()\n",
    "print('PC2ï¼ˆç¬¬2ä¸»æˆåˆ†ï¼‰: ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ã®å‚¾ãå¤‰å‹•ï¼ˆã‚¹ãƒ†ã‚£ãƒ¼ãƒ—åŒ–/ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼‰')\n",
    "print('  â†’ çŸ­æœŸé‡‘åˆ©ã¨é•·æœŸé‡‘åˆ©ã®å·®ãŒå¤‰åŒ–ã™ã‚‹å‹•ã')\n",
    "print()\n",
    "print('PC3ï¼ˆç¬¬3ä¸»æˆåˆ†ï¼‰: ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ã®æ›²ç‡å¤‰å‹•ï¼ˆãƒã‚¿ãƒ•ãƒ©ã‚¤ï¼‰')\n",
    "print('  â†’ ä¸­æœŸé‡‘åˆ©ãŒçŸ­æœŸãƒ»é•·æœŸã«å¯¾ã—ã¦ç›¸å¯¾çš„ã«å¤‰åŒ–ã™ã‚‹å‹•ã')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã‚’DataFrameã«å¤‰æ›ã—ã¦ä¿å­˜\n",
    "pca_scores_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(X_pca.shape[1])],\n",
    "    index=valid_dates\n",
    ")\n",
    "pca_scores_df.index.name = 'trade_date'\n",
    "\n",
    "# è¡¨ç¤º\n",
    "print('ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ï¼ˆæœ€æ–°10æ—¥åˆ†ï¼‰:')\n",
    "print(pca_scores_df.head(10))\n",
    "\n",
    "# CSVå‡ºåŠ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "# output_path = os.path.join(project_root, 'data_files', 'pca_scores.csv')\n",
    "# pca_scores_df.to_csv(output_path)\n",
    "# print(f'\\nâœ… ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€æ—¥æœ¬å›½å‚µã®ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸»æˆåˆ†åˆ†æã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚\n",
    "\n",
    "### å®Ÿæ–½å†…å®¹\n",
    "1. âœ… æœ€æ–°100å–¶æ¥­æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "2. âœ… æ®‹å­˜æœŸé–“0.5å¹´æœªæº€ã‚’é™¤å¤–\n",
    "3. âœ… å…¨æ—¥ä»˜ã®æ®‹å­˜æœŸé–“ã®å’Œé›†åˆã‚’ä½œæˆ\n",
    "4. âœ… 3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§æ¬ æå€¤ã‚’è£œå®Œ\n",
    "5. âœ… ä¸»æˆåˆ†åˆ†æã‚’å®Ÿè¡Œ\n",
    "6. âœ… å¯„ä¸ç‡ã€å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã€ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢ã‚’å¯è¦–åŒ–\n",
    "\n",
    "### ä¸»ãªç™ºè¦‹\n",
    "- **PC1ï¼ˆæ°´æº–å¤‰å‹•ï¼‰**: ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–å…¨ä½“ã®ä¸Šä¸‹å‹•ã‚’è¡¨ç¾\n",
    "- **PC2ï¼ˆå‚¾ãå¤‰å‹•ï¼‰**: çŸ­æœŸã¨é•·æœŸã®é‡‘åˆ©å·®ã®å¤‰åŒ–ã‚’è¡¨ç¾\n",
    "- **PC3ï¼ˆæ›²ç‡å¤‰å‹•ï¼‰**: ä¸­æœŸé‡‘åˆ©ã®ç›¸å¯¾çš„ãªå‹•ãã‚’è¡¨ç¾\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ä¸»æˆåˆ†ã¯ã€é‡‘åˆ©ãƒªã‚¹ã‚¯ç®¡ç†ã‚„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã«æ´»ç”¨ã§ãã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
