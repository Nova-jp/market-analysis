{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Amount Time Series Analysis\n",
    "\n",
    "## Objective\n",
    "- Identify time series inconsistencies in bond_data.market_amount\n",
    "- Visualize negative values and abnormal jumps\n",
    "- Determine specific correction strategies\n",
    "\n",
    "## Expected Problem Patterns\n",
    "1. **Negative values**: BOJ holdings > Cumulative issuance (purchase operations) → Normal state, acceptable\n",
    "2. **Data gaps**: Incomplete data in bond_auction or boj_holdings\n",
    "3. **Calculation timing issues**: Forward-fill logic problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client\n",
    "\n",
    "# Set plot style (no Japanese font needed)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "# Supabase connection\n",
    "load_dotenv()\n",
    "url = os.getenv('SUPABASE_URL')\n",
    "key = os.getenv('SUPABASE_KEY')\n",
    "supabase = create_client(url, key)\n",
    "\n",
    "print(f\"✅ Supabase connected: {url[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_timeseries(bond_code: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get time series data for a specific bond\n",
    "    \n",
    "    Args:\n",
    "        bond_code: Bond code (9 digits)\n",
    "        start_date: Start date (YYYY-MM-DD), optional\n",
    "        end_date: End date (YYYY-MM-DD), optional\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: trade_date, bond_code, bond_name, market_amount, due_date\n",
    "        If start_date and end_date are None, returns all available data from the earliest date\n",
    "    \"\"\"\n",
    "    query = supabase.table('bond_data') \\\n",
    "        .select('trade_date, bond_code, bond_name, market_amount, due_date') \\\n",
    "        .eq('bond_code', bond_code) \\\n",
    "        .order('trade_date')\n",
    "    \n",
    "    if start_date:\n",
    "        query = query.gte('trade_date', start_date)\n",
    "    if end_date:\n",
    "        query = query.lte('trade_date', end_date)\n",
    "    \n",
    "    result = query.execute()\n",
    "    \n",
    "    if not result.data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(result.data)\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    df['market_amount'] = pd.to_numeric(df['market_amount'], errors='coerce')\n",
    "    \n",
    "    print(f\"Retrieved {len(df)} records from {df['trade_date'].min()} to {df['trade_date'].max()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_bond_codes_with_market_amount(limit: int = 100) -> list:\n",
    "    \"\"\"Get bond codes that have market_amount data\"\"\"\n",
    "    result = supabase.table('bond_data') \\\n",
    "        .select('bond_code') \\\n",
    "        .not_.is_('market_amount', 'null') \\\n",
    "        .limit(limit) \\\n",
    "        .execute()\n",
    "    \n",
    "    if not result.data:\n",
    "        return []\n",
    "    \n",
    "    bond_codes = list(set([row['bond_code'] for row in result.data]))\n",
    "    return bond_codes\n",
    "\n",
    "\n",
    "def get_auction_and_boj_data(bond_code: str) -> dict:\n",
    "    \"\"\"Get raw auction and BOJ holdings data for verification\"\"\"\n",
    "    # Auction data\n",
    "    auction = supabase.table('bond_auction') \\\n",
    "        .select('auction_date, allocated_amount') \\\n",
    "        .eq('bond_code', bond_code) \\\n",
    "        .order('auction_date') \\\n",
    "        .execute()\n",
    "    \n",
    "    # BOJ holdings data\n",
    "    boj = supabase.table('boj_holdings') \\\n",
    "        .select('data_date, face_value') \\\n",
    "        .eq('bond_code', bond_code) \\\n",
    "        .order('data_date') \\\n",
    "        .execute()\n",
    "    \n",
    "    return {\n",
    "        'auction': pd.DataFrame(auction.data) if auction.data else pd.DataFrame(),\n",
    "        'boj': pd.DataFrame(boj.data) if boj.data else pd.DataFrame()\n",
    "    }\n",
    "\n",
    "print(\"✅ Data retrieval functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(df: pd.DataFrame, threshold_pct: float = 20.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect time series anomalies\n",
    "    \n",
    "    Args:\n",
    "        df: Time series DataFrame (trade_date, market_amount)\n",
    "        threshold_pct: Anomaly threshold (% change from previous day)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing only anomalous data\n",
    "    \"\"\"\n",
    "    df = df.sort_values('trade_date').copy()\n",
    "    \n",
    "    # Calculate day-over-day change\n",
    "    df['pct_change'] = df['market_amount'].pct_change() * 100\n",
    "    df['abs_change'] = df['market_amount'].diff()\n",
    "    \n",
    "    # Anomaly flags\n",
    "    df['is_negative'] = df['market_amount'] < 0\n",
    "    df['is_large_jump'] = df['pct_change'].abs() > threshold_pct\n",
    "    df['is_anomaly'] = df['is_negative'] | df['is_large_jump']\n",
    "    \n",
    "    return df[df['is_anomaly']].copy()\n",
    "\n",
    "\n",
    "def analyze_time_gaps(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Analyze data gap periods\"\"\"\n",
    "    df = df.sort_values('trade_date').copy()\n",
    "    df['date_diff'] = df['trade_date'].diff().dt.days\n",
    "    \n",
    "    # Detect gaps longer than 7 days (5 business days)\n",
    "    gaps = df[df['date_diff'] > 7].copy()\n",
    "    return gaps\n",
    "\n",
    "print(\"✅ Anomaly detection functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bond_timeseries(bond_code: str, figsize=(16, 10)):\n",
    "    \"\"\"\n",
    "    Visualize bond time series in detail\n",
    "    - Market amount\n",
    "    - Cumulative issuance vs BOJ holdings\n",
    "    - Day-over-day change rate\n",
    "    \"\"\"\n",
    "    # Get data\n",
    "    df = get_bond_timeseries(bond_code)\n",
    "    raw_data = get_auction_and_boj_data(bond_code)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"No data found for: {bond_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Detect anomalies\n",
    "    anomalies = detect_anomalies(df)\n",
    "    \n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=figsize, sharex=True)\n",
    "    \n",
    "    # --- Subplot 1: Market Amount ---\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(df['trade_date'], df['market_amount'], 'b-', linewidth=1.5, label='Market Amount')\n",
    "    ax1.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    # Highlight anomalies\n",
    "    if not anomalies.empty:\n",
    "        ax1.scatter(anomalies['trade_date'], anomalies['market_amount'], \n",
    "                   color='red', s=50, zorder=5, label='Anomalies')\n",
    "    \n",
    "    ax1.set_ylabel('Market Amount (100M JPY)', fontsize=12)\n",
    "    ax1.set_title(f'{df.iloc[0][\"bond_name\"]} ({bond_code}) - Time Series Analysis', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- Subplot 2: Cumulative Issuance vs BOJ Holdings ---\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    if not raw_data['auction'].empty:\n",
    "        auction_df = raw_data['auction'].copy()\n",
    "        auction_df['auction_date'] = pd.to_datetime(auction_df['auction_date'])\n",
    "        auction_df['cumulative'] = auction_df['allocated_amount'].cumsum()\n",
    "        ax2.plot(auction_df['auction_date'], auction_df['cumulative'], \n",
    "                'g-', linewidth=1.5, label='Cumulative Issuance')\n",
    "    \n",
    "    if not raw_data['boj'].empty:\n",
    "        boj_df = raw_data['boj'].copy()\n",
    "        boj_df['data_date'] = pd.to_datetime(boj_df['data_date'])\n",
    "        ax2.plot(boj_df['data_date'], boj_df['face_value'], \n",
    "                'r-', linewidth=1.5, label='BOJ Holdings')\n",
    "    \n",
    "    ax2.set_ylabel('Amount (100M JPY)', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- Subplot 3: Day-over-day Change Rate ---\n",
    "    ax3 = axes[2]\n",
    "    df_copy = df.copy()\n",
    "    df_copy['pct_change'] = df_copy['market_amount'].pct_change() * 100\n",
    "    \n",
    "    ax3.bar(df_copy['trade_date'], df_copy['pct_change'], \n",
    "           color='gray', alpha=0.7, width=1)\n",
    "    ax3.axhline(y=20, color='red', linestyle='--', linewidth=1, alpha=0.5, label='±20% Threshold')\n",
    "    ax3.axhline(y=-20, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    ax3.set_xlabel('Date', fontsize=12)\n",
    "    ax3.set_ylabel('Change Rate (%)', fontsize=12)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'timeseries': df,\n",
    "        'anomalies': anomalies,\n",
    "        'raw_data': raw_data\n",
    "    }\n",
    "\n",
    "print(\"✅ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Bond Analysis (10-Year Bond #372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample bond (10-Year Bond #372)\n",
    "SAMPLE_BOND_CODE = '003720067'\n",
    "\n",
    "# Run time series analysis\n",
    "result = plot_bond_timeseries(SAMPLE_BOND_CODE)\n",
    "\n",
    "# Display anomaly summary\n",
    "if result and not result['anomalies'].empty:\n",
    "    print(\"\\n=== Anomaly Summary ===\")\n",
    "    print(result['anomalies'][['trade_date', 'market_amount', 'pct_change', 'abs_change', 'is_negative', 'is_large_jump']])\n",
    "else:\n",
    "    print(\"\\nNo anomalies detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Analysis for Multiple Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_anomaly_detection(bond_codes: list) -> pd.DataFrame:\n",
    "    \"\"\"Detect anomalies across multiple bonds\"\"\"\n",
    "    all_anomalies = []\n",
    "    \n",
    "    for i, bond_code in enumerate(bond_codes):\n",
    "        print(f\"Analyzing {i+1}/{len(bond_codes)}: {bond_code}\")\n",
    "        df = get_bond_timeseries(bond_code)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        anomalies = detect_anomalies(df)\n",
    "        if not anomalies.empty:\n",
    "            anomalies['bond_code'] = bond_code\n",
    "            all_anomalies.append(anomalies)\n",
    "    \n",
    "    if not all_anomalies:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(all_anomalies, ignore_index=True)\n",
    "\n",
    "\n",
    "# Example: Analyze first 20 bonds\n",
    "bond_codes = get_all_bond_codes_with_market_amount(limit=100)\n",
    "print(f\"Total bonds with market_amount: {len(bond_codes)}\")\n",
    "\n",
    "batch_anomalies = batch_anomaly_detection(bond_codes[:20])  # Sample 20 bonds\n",
    "print(f\"\\nTotal anomalies detected: {len(batch_anomalies)}\")\n",
    "if not batch_anomalies.empty:\n",
    "    display(batch_anomalies.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Anomaly Pattern Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_anomaly_patterns(anomalies_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Classify anomaly patterns\"\"\"\n",
    "    if anomalies_df.empty:\n",
    "        print(\"No anomalies to classify\")\n",
    "        return {}\n",
    "    \n",
    "    summary = {\n",
    "        'total_anomalies': len(anomalies_df),\n",
    "        'negative_values': len(anomalies_df[anomalies_df['is_negative']]),\n",
    "        'large_jumps': len(anomalies_df[anomalies_df['is_large_jump']]),\n",
    "        'avg_pct_change': anomalies_df['pct_change'].mean(),\n",
    "        'max_pct_change': anomalies_df['pct_change'].max(),\n",
    "        'min_pct_change': anomalies_df['pct_change'].min()\n",
    "    }\n",
    "    \n",
    "    print(\"=== Anomaly Pattern Classification ===\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "# Run pattern classification\n",
    "if not batch_anomalies.empty:\n",
    "    pattern_summary = classify_anomaly_patterns(batch_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Specific Bond (Custom Input)\n",
    "\n",
    "Use this cell to analyze any bond by entering its bond_code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter bond code here (9 digits)\n",
    "CUSTOM_BOND_CODE = '003720067'  # Change this to analyze different bonds\n",
    "\n",
    "# Run analysis\n",
    "custom_result = plot_bond_timeseries(CUSTOM_BOND_CODE)\n",
    "\n",
    "if custom_result:\n",
    "    print(f\"\\n=== Analysis Results for {CUSTOM_BOND_CODE} ===\")\n",
    "    print(f\"Total data points: {len(custom_result['timeseries'])}\")\n",
    "    print(f\"Date range: {custom_result['timeseries']['trade_date'].min()} to {custom_result['timeseries']['trade_date'].max()}\")\n",
    "    print(f\"Anomalies detected: {len(custom_result['anomalies'])}\")\n",
    "    \n",
    "    if not custom_result['anomalies'].empty:\n",
    "        print(\"\\nAnomalies:\")\n",
    "        display(custom_result['anomalies'][['trade_date', 'market_amount', 'pct_change', 'is_negative', 'is_large_jump']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Investigation Summary\n",
    "\n",
    "### Findings\n",
    "(Record analysis results here)\n",
    "\n",
    "### Correction Strategy\n",
    "(Record correction strategy here)\n",
    "\n",
    "### Next Steps\n",
    "1. Create list of problematic bonds\n",
    "2. Correct calculation logic if needed\n",
    "3. Re-calculate data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
